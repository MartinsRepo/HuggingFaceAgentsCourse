{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alfred the Mail Sorting Butler: A LangGraph Example\n",
    "\n",
    "In this notebook, **we're going to build a complete email processing workflow using LangGraph**.\n",
    "\n",
    "This notebook is part of the <a href=\"https://www.hf.co/learn/agents-course\">Hugging Face Agents Course</a>, a free course from beginner to expert, where you learn to build Agents.\n",
    "\n",
    "![Agents course share](https://huggingface.co/datasets/agents-course/course-images/resolve/main/en/communication/share.png)\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "In this notebook, you'll learn how to:\n",
    "1. Set up a LangGraph workflow\n",
    "2. Define state and nodes for email processing\n",
    "3. Create conditional branching in a graph\n",
    "4. Connect an LLM for classification and content generation\n",
    "5. Visualize the workflow graph\n",
    "6. Execute the workflow with example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the required packages\n",
    "#%pip install -q langgraph langchain_openai langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up Our Environment\n",
    "\n",
    "First, let's import all the necessary libraries. LangGraph provides the graph structure, while LangChain offers convenient interfaces for working with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Initialize the model with the required parameters\n",
    "openai_model_name =  \"gpt-4o-mini\"\n",
    "model = ChatOpenAI(model=openai_model_name, temperature=0, api_key=open_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define Our State\n",
    "\n",
    "In LangGraph, **State** is the central concept. It represents all the information that flows through our workflow.\n",
    "\n",
    "For Alfred's email processing system, we need to track:\n",
    "- The email being processed\n",
    "- Whether it's spam or not\n",
    "- The draft response (for legitimate emails)\n",
    "- Conversation history with the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]   \n",
    "    # Analysis and decisions     \n",
    "    is_spam: Optional[bool]      \n",
    "    # Reason why the email was marked as spam\n",
    "    spam_reason: Optional[str]    \n",
    "    # Category of the email (inquiry, complaint, etc.) \n",
    "    email_category: Optional[str]   \n",
    "    # Response generation\n",
    "    draft_response: Optional[str]   \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Define Our Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7744ae83c260>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]\n",
    "    is_spam: Optional[bool]\n",
    "    draft_response: Optional[str]\n",
    "    messages: List[Dict[str, Any]]\n",
    "\n",
    "# Define nodes\n",
    "def read_email(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    return {}\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler of Mr wayne and it's SECRET identity Batman, analyze this email and determine if it is spam or legitimate and should be brought to Mr wayne's attention.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "First, determine if this email is spam.\n",
    "answer with SPAM or HAM if it's legitimate. Only reurn the answer\n",
    "Answer :\n",
    "    \"\"\"\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    response_text = response.content.lower()\n",
    "    print(response_text)\n",
    "    is_spam = \"spam\" in response_text and \"ham\" not in response_text\n",
    "    \n",
    "    if not is_spam:\n",
    "        new_messages = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    else :\n",
    "        new_messages = state.get(\"messages\", [])\n",
    "    \n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    print(f\"Alfred has marked the email as spam.\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    return {}\n",
    "\n",
    "def drafting_response(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler, draft a polite preliminary response to this email.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "Draft a brief, professional response that Mr. Wayne can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "    \n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "    \n",
    "    return {\n",
    "        \"draft_response\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "def notify_mr_wayne(state: EmailState):\n",
    "    email = state[\"email\"]\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\"*50)\n",
    "    print(state[\"draft_response\"])\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "    \n",
    "    return {}\n",
    "\n",
    "# Define routing logic\n",
    "def route_email(state: EmailState) -> str:\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\"\n",
    "\n",
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email) # the read_email node executes the read_mail function\n",
    "email_graph.add_node(\"classify_email\", classify_email) # the classify_email node will execute the classify_email function\n",
    "email_graph.add_node(\"handle_spam\", handle_spam) #same logic \n",
    "email_graph.add_node(\"drafting_response\", drafting_response) #same logic\n",
    "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne) # same logic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Our Routing Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'START' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Add edges\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m email_graph.add_edge(\u001b[43mSTART\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33mread_email\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# After starting we go to the \"read_email\" node\u001b[39;00m\n\u001b[32m      4\u001b[39m email_graph.add_edge(\u001b[33m\"\u001b[39m\u001b[33mread_email\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mclassify_email\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# after_reading we classify\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Add conditional edges\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'START' is not defined"
     ]
    }
   ],
   "source": [
    "# Add edges\n",
    "email_graph.add_edge(START, \"read_email\") # After starting we go to the \"read_email\" node\n",
    "\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\") # after_reading we classify\n",
    "\n",
    "# Add conditional edges\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\", # after classify, we run the \"route_email\" function\"\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\", # if it return \"Spam\", we go the \"handle_span\" node\n",
    "        \"legitimate\": \"drafting_response\" # and if it's legitimate, we go to the \"drafting response\" node\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add final edges\n",
    "email_graph.add_edge(\"handle_spam\", END) # after handling spam we always end\n",
    "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")\n",
    "email_graph.add_edge(\"notify_mr_wayne\", END) # after notifyinf Me wayne, we can end  too\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create the StateGraph and Define Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found edge starting at unknown node 'START'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Compile the graph\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m compiled_graph = \u001b[43memail_graph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/langraphagents/lib/python3.12/site-packages/langgraph/graph/state.py:602\u001b[39m, in \u001b[36mStateGraph.compile\u001b[39m\u001b[34m(self, checkpointer, store, interrupt_before, interrupt_after, debug, name)\u001b[39m\n\u001b[32m    599\u001b[39m interrupt_after = interrupt_after \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# validate the graph\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    603\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    604\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m*\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m    606\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[38;5;66;03m# prepare output channels\u001b[39;00m\n\u001b[32m    611\u001b[39m output_channels = (\n\u001b[32m    612\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m__root__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    613\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.schemas[\u001b[38;5;28mself\u001b[39m.output]) == \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    619\u001b[39m     ]\n\u001b[32m    620\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/langraphagents/lib/python3.12/site-packages/langgraph/graph/graph.py:264\u001b[39m, in \u001b[36mGraph.validate\u001b[39m\u001b[34m(self, interrupt)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.nodes \u001b[38;5;129;01mand\u001b[39;00m source != START:\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound edge starting at unknown node \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m START \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m all_sources:\n\u001b[32m    267\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    268\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mGraph must have an entrypoint: add at least one edge from START to another node\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    269\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found edge starting at unknown node 'START'"
     ]
    }
   ],
   "source": [
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Example emails for testing\n",
    "legitimate_email = {\n",
    "    \"sender\": \"Joker\",\n",
    "    \"subject\": \"Found you Batman ! \",\n",
    "    \"body\": \"Mr. Wayne,I found your secret identity ! I know you're batman ! Ther's no denying it, I have proof of that and I'm coming to find you soon. I'll get my revenge. JOKER\"\n",
    "}\n",
    "\n",
    "spam_email = {\n",
    "    \"sender\": \"Crypto bro\",\n",
    "    \"subject\": \"The best investment of 2025\",\n",
    "    \"body\": \"Mr Wayne, I just launched an ALT coin and want you to buy some !\"\n",
    "}\n",
    "# Process legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"draft_response\": None,\n",
    "    \"messages\": []\n",
    "}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraphagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

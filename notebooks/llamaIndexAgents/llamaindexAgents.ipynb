{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install llama-index datasets llama-index-callbacks-arize-phoenix llama-index-vector-stores-chroma llama-index-llms-huggingface-api -U -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "open_api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from llama_index.core.agent.workflow import AgentWorkflow, ToolCallResult, AgentStream\n",
    "\n",
    "\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "def subtract(a: int, b: int) -> int:\n",
    "    \"\"\"Subtract two numbers\"\"\"\n",
    "    return a - b\n",
    "\n",
    "\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "def divide(a: int, b: int) -> int:\n",
    "    \"\"\"Divide two numbers\"\"\"\n",
    "    return a / b\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "# Initialize the model with the required parameters\n",
    "openai_model_name =  \"gpt-4o-mini\"\n",
    "model = OpenAI(model=openai_model_name, api_key=open_api_key)\n",
    "\n",
    "agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[subtract, multiply, divide, add],\n",
    "    llm=model,\n",
    "    system_prompt=\"You are a math agent that can add, subtract, multiply, and divide numbers using provided tools.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  add {'a': 2, 'b': 2} => 4\n",
      "\n",
      "Called tool:  multiply {'a': 4, 'b': 2} => 8\n",
      "The result of \\((2 + 2) * 2\\) is \\(8\\)."
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='The result of \\\\((2 + 2) * 2\\\\) is \\\\(8\\\\).')]), tool_calls=[ToolCallResult(tool_name='add', tool_kwargs={'a': 2, 'b': 2}, tool_id='call_FpsIS2DZO2xxkpIzGhYBRGAQ', tool_output=ToolOutput(content='4', tool_name='add', raw_input={'args': (), 'kwargs': {'a': 2, 'b': 2}}, raw_output=4, is_error=False), return_direct=False), ToolCallResult(tool_name='multiply', tool_kwargs={'a': 4, 'b': 2}, tool_id='call_D8BbkAm65tQvFsocCzKslQa0', tool_output=ToolOutput(content='8', tool_name='multiply', raw_input={'args': (), 'kwargs': {'a': 4, 'b': 2}}, raw_output=8, is_error=False), return_direct=False)], raw={'id': 'chatcmpl-BBKzZi4HI6bPbgAynzD62ql4w3pZG', 'choices': [{'delta': {'content': None, 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'created': 1742042001, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion.chunk', 'service_tier': 'default', 'system_fingerprint': 'fp_3267753c5d', 'usage': None}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handler = agent.run(\"What is (2 + 2) * 2?\")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='Your name is Bob.')]), tool_calls=[], raw={'id': 'chatcmpl-BBKzahHKeosJeWiLXbSeve60aqi3U', 'choices': [{'delta': {'content': None, 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'created': 1742042002, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion.chunk', 'service_tier': 'default', 'system_fingerprint': 'fp_3267753c5d', 'usage': None}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llama_index.core.workflow import Context\n",
    "\n",
    "ctx = Context(agent)\n",
    "\n",
    "response = await agent.run(\"My name is Bob.\", ctx=ctx)\n",
    "response = await agent.run(\"What was my name again?\", ctx=ctx)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "\n",
    "# Create a vector store\n",
    "db = chromadb.PersistentClient(path=\"./alfred_chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"alfred\")\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "\n",
    "# Create a query engine\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store=vector_store, embed_model=embed_model\n",
    ")\n",
    "query_engine = index.as_query_engine(llm=model)\n",
    "query_engine_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=query_engine,\n",
    "    name=\"personas\",\n",
    "    description=\"descriptions for various types of personas\",\n",
    "    return_direct=False,\n",
    ")\n",
    "\n",
    "# Create a RAG agent\n",
    "query_engine_agent = AgentWorkflow.from_tools_or_functions(\n",
    "    tools_or_functions=[query_engine_tool],\n",
    "    llm=model,\n",
    "    system_prompt=\"You are a helpful assistant that has access to a database containing persona descriptions. \",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Called tool:  personas {'input': 'science fiction'} => Empty Response\n",
      "It seems that there are no persona descriptions available in the database for \"science fiction.\" If you have another topic or specific persona in mind, please let me know!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AgentOutput(response=ChatMessage(role=<MessageRole.ASSISTANT: 'assistant'>, additional_kwargs={}, blocks=[TextBlock(block_type='text', text='It seems that there are no persona descriptions available in the database for \"science fiction.\" If you have another topic or specific persona in mind, please let me know!')]), tool_calls=[ToolCallResult(tool_name='personas', tool_kwargs={'input': 'science fiction'}, tool_id='call_WpGB82KXXo4emLfnFHLUVrXr', tool_output=ToolOutput(content='Empty Response', tool_name='personas', raw_input={'input': 'science fiction'}, raw_output=Response(response='Empty Response', source_nodes=[], metadata=None), is_error=False), return_direct=False)], raw={'id': 'chatcmpl-BBL5aMOhZmrnfmd79LzKjzbh8nYaT', 'choices': [{'delta': {'content': None, 'function_call': None, 'refusal': None, 'role': None, 'tool_calls': None}, 'finish_reason': 'stop', 'index': 0, 'logprobs': None}], 'created': 1742042374, 'model': 'gpt-4o-mini-2024-07-18', 'object': 'chat.completion.chunk', 'service_tier': 'default', 'system_fingerprint': 'fp_3267753c5d', 'usage': None}, current_agent_name='Agent')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# works Jupyter notebook only, but not py export\n",
    "'''\n",
    "handler = query_engine_agent.run(\n",
    "    \"Search the database for 'science fiction' and return some persona descriptions.\"\n",
    ")\n",
    "async for ev in handler.stream_events():\n",
    "    if isinstance(ev, ToolCallResult):\n",
    "        print(\"\")\n",
    "        print(\"Called tool: \", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "    elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "        print(ev.delta, end=\"\", flush=True)\n",
    "\n",
    "resp = await handler\n",
    "resp\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    # Run first agent query\n",
    "    handler = agent.run(\"What is (2 + 2) * 2?\")\n",
    "    async for ev in handler.stream_events():\n",
    "        if isinstance(ev, ToolCallResult):\n",
    "            print(\"\\nCalled tool:\", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "        elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "            print(ev.delta, end=\"\", flush=True)\n",
    "    resp = await handler\n",
    "    print(\"\\nFinal response:\", resp)\n",
    "    \n",
    "    # Run conversation using context\n",
    "    ctx = Context(agent)\n",
    "    response = await agent.run(\"My name is Bob.\", ctx=ctx)\n",
    "    response = await agent.run(\"What was my name again?\", ctx=ctx)\n",
    "    print(\"\\nConversation response:\", response)\n",
    "    \n",
    "    # Run query engine agent query\n",
    "    handler = query_engine_agent.run(\n",
    "        \"Search the database for 'science fiction' and return some persona descriptions.\"\n",
    "    )\n",
    "    async for ev in handler.stream_events():\n",
    "        if isinstance(ev, ToolCallResult):\n",
    "            print(\"\\nCalled tool:\", ev.tool_name, ev.tool_kwargs, \"=>\", ev.tool_output)\n",
    "        elif isinstance(ev, AgentStream):  # showing the thought process\n",
    "            print(ev.delta, end=\"\", flush=True)\n",
    "    resp = await handler\n",
    "    print(\"\\nQuery engine final response:\", resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'asyncio' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[43masyncio\u001b[49m.run(main())\n",
      "\u001b[31mNameError\u001b[39m: name 'asyncio' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaIndexAgents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
